{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4d7006",
   "metadata": {},
   "source": [
    "# CIFAR-10 Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2456c6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Model created with 1149770 parameters\n"
     ]
    }
   ],
   "source": [
    "# Test cell - this should show execution time\n",
    "data_config = DataConfig(batch_size=32)\n",
    "data = CIFAR10Data(data_config)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "model = build_model(\"cnn\")\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d95d394",
   "metadata": {},
   "source": [
    "## Dependencies and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a156b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from dataclasses import dataclass\n",
    "from types import SimpleNamespace\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def accuracy(outputs, targets):\n",
    "    _, preds = outputs.max(1)\n",
    "    return preds.eq(targets).float().mean().item()\n",
    "\n",
    "def save_checkpoint(state, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(state, path)\n",
    "\n",
    "def load_checkpoint(path, map_location=None):\n",
    "    return torch.load(path, map_location=map_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9570a3f",
   "metadata": {},
   "source": [
    "## Data Config & Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataConfig:\n",
    "    data_dir: str = \"./\"   # parent dir of cifar-10-batches-py\n",
    "    batch_size: int = 128\n",
    "    num_workers: int = 4\n",
    "    randaugment: bool = False\n",
    "    cutout: bool = False\n",
    "    cutout_holes: int = 1\n",
    "    cutout_len: int = 16\n",
    "\n",
    "class Cutout(object):\n",
    "    def __init__(self, n_holes: int = 1, length: int = 16):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "    def __call__(self, img):\n",
    "        h, w = img.size(1), img.size(2)\n",
    "        mask = torch.ones((h, w), dtype=torch.float32)\n",
    "        for _ in range(self.n_holes):\n",
    "            y = np.random.randint(h); x = np.random.randint(w)\n",
    "            y1 = np.clip(y - self.length // 2, 0, h); y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w); x2 = np.clip(x + self.length // 2, 0, w)\n",
    "            mask[int(y1):int(y2), int(x1):int(x2)] = 0.\n",
    "        mask = mask.expand_as(img)\n",
    "        return img * mask\n",
    "\n",
    "class CIFAR10Data:\n",
    "    def __init__(self, cfg: DataConfig):\n",
    "        self.cfg = cfg  # Store the config as an instance variable\n",
    "        \n",
    "        normalize = transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                                         [0.2023, 0.1994, 0.2010])\n",
    "        train_tfms = [transforms.RandomCrop(32, padding=4),\n",
    "                      transforms.RandomHorizontalFlip()]\n",
    "        if cfg.randaugment: train_tfms.insert(0, RandAugment())\n",
    "        train_tfms += [transforms.ToTensor(), normalize]\n",
    "        if cfg.cutout: train_tfms.append(Cutout(cfg.cutout_holes, cfg.cutout_len))\n",
    "        self.train_transform = transforms.Compose(train_tfms)\n",
    "        self.test_transform  = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "        self.train_set = datasets.CIFAR10(cfg.data_dir, train=True, download=True, transform=self.train_transform)\n",
    "        self.val_set   = datasets.CIFAR10(cfg.data_dir, train=True, download=False, transform=self.test_transform)\n",
    "        self.test_set  = datasets.CIFAR10(cfg.data_dir, train=False, download=True, transform=self.test_transform)\n",
    "\n",
    "        num_train = len(self.train_set)\n",
    "        split = 5000\n",
    "        train_idx, val_idx = list(range(num_train - split)), list(range(num_train - split, num_train))\n",
    "        self.train_subset = torch.utils.data.Subset(self.train_set, train_idx)\n",
    "        self.val_subset   = torch.utils.data.Subset(self.val_set,   val_idx)\n",
    "    def loaders(self):\n",
    "        train_loader = DataLoader(self.train_subset, batch_size=self.cfg.batch_size, shuffle=True,\n",
    "                                  num_workers=self.cfg.num_workers, pin_memory=True)\n",
    "        val_loader = DataLoader(self.val_subset, batch_size=self.cfg.batch_size, shuffle=False,\n",
    "                                num_workers=self.cfg.num_workers, pin_memory=True)\n",
    "        test_loader = DataLoader(self.test_set, batch_size=self.cfg.batch_size, shuffle=False,\n",
    "                                 num_workers=self.cfg.num_workers, pin_memory=True)\n",
    "        return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ae8dd",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc82f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x).view(x.size(0), -1))\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion=1\n",
    "    def __init__(self,in_planes,planes,stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(in_planes,planes,3,stride,1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(planes)\n",
    "        self.conv2=nn.Conv2d(planes,planes,3,1,1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(planes)\n",
    "        self.shortcut=nn.Sequential()\n",
    "        if stride!=1 or in_planes!=planes:\n",
    "            self.shortcut=nn.Sequential(nn.Conv2d(in_planes,planes,1,stride,bias=False), nn.BatchNorm2d(planes))\n",
    "    def forward(self,x):\n",
    "        out=F.relu(self.bn1(self.conv1(x)))\n",
    "        out=self.bn2(self.conv2(out))\n",
    "        out+=self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "class CIFARResNet18(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes=64\n",
    "        self.conv1=nn.Conv2d(3,64,3,1,1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.layer1=self._make_layer(64,2,1)\n",
    "        self.layer2=self._make_layer(128,2,2)\n",
    "        self.layer3=self._make_layer(256,2,2)\n",
    "        self.layer4=self._make_layer(512,2,2)\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc=nn.Linear(512,num_classes)\n",
    "    def _make_layer(self,planes,blocks,stride):\n",
    "        layers=[BasicBlock(self.in_planes,planes,stride)]\n",
    "        self.in_planes=planes\n",
    "        for _ in range(1,blocks): layers.append(BasicBlock(self.in_planes,planes))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.bn1(self.conv1(x)))\n",
    "        x=self.layer1(x); x=self.layer2(x); x=self.layer3(x); x=self.layer4(x)\n",
    "        return self.fc(self.avgpool(x).view(x.size(0),-1))\n",
    "\n",
    "def build_model(name,num_classes=10):\n",
    "    if name in [\"cnn\",\"baseline\"]: return BasicCNN(num_classes)\n",
    "    if name in [\"resnet18\",\"resnet\"]: return CIFARResNet18(num_classes)\n",
    "    raise ValueError(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd601d2",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a631f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(args):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() and not args.cpu else \"cpu\")\n",
    "    ckpt=load_checkpoint(args.ckpt,map_location=device)\n",
    "    model_name=args.model if args.model else ckpt[\"args\"][\"model\"]\n",
    "    model=build_model(model_name,10).to(device); model.load_state_dict(ckpt[\"model\"]); model.eval()\n",
    "    data=CIFAR10Data(DataConfig(args.data_dir,args.batch_size,args.workers))\n",
    "    _,_,test_loader=data.loaders()\n",
    "    all_preds,all_targets=[],[]\n",
    "    for images,targets in tqdm(test_loader,desc=\"Evaluating\"):\n",
    "        preds=model(images.to(device)).argmax(1).cpu().numpy()\n",
    "        all_preds.append(preds); all_targets.append(targets.numpy())\n",
    "    y_pred,y_true=np.concatenate(all_preds),np.concatenate(all_targets)\n",
    "    print(classification_report(y_true,y_pred,digits=4,target_names=[\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]))\n",
    "    print(confusion_matrix(y_true,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd5fa9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(args):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() and not args.cpu else \"cpu\")\n",
    "    ckpt=load_checkpoint(args.ckpt,map_location=device)\n",
    "    model_name=args.model if args.model else ckpt[\"args\"][\"model\"]\n",
    "    model=build_model(model_name,10).to(device)\n",
    "    model.load_state_dict(ckpt[\"model\"]); model.eval()\n",
    "    data=CIFAR10Data(DataConfig(args.data_dir,args.batch_size,args.workers))\n",
    "    _,_,test_loader=data.loaders()\n",
    "    all_preds,all_targets=[],[]\n",
    "    for images,targets in tqdm(test_loader,desc=\"Evaluating\"):\n",
    "        preds=model(images.to(device)).argmax(1).cpu().numpy()\n",
    "        all_preds.append(preds); all_targets.append(targets.numpy())\n",
    "    y_pred,y_true=np.concatenate(all_preds),np.concatenate(all_targets)\n",
    "    print(classification_report(y_true,y_pred,digits=4,\n",
    "          target_names=[\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]))\n",
    "    print(confusion_matrix(y_true,y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
